# =============================================================================
# smartedu_fetch_all.sh  â€”â€”  Shell + Python polyglot (v1.0)
# -----------------------------------------------------------------------------
# æ–°å¢ï¼š
#  â€¢ æ•´è¼ªçµæŸå¾Œè‡ªå‹•é‡è©¦ï¼ˆé è¨­ 2 è¼ªï¼Œå¯ç”¨ -T N èª¿æ•´ï¼›0 è¡¨ç¤ºé—œé–‰ï¼‰ã€‚
#  â€¢ æ¯è¼ªé‡è©¦åƒ…é‡å°ä¸Šè¼ªå¤±æ•—æ¸…å–®ï¼ŒæˆåŠŸå³å¯«å› index.jsonï¼Œä»å¤±æ•—ä¿ç•™åˆ° failed.jsonã€‚
#  â€¢ æœ€çµ‚è‹¥ä»æœ‰å¤±æ•—ï¼Œæ¸…æ™°æç¤ºç”¨æˆ¶å¯å†æ¬¡é‹è¡Œæˆ–ç”¨ -R åƒ…é‡è©¦å¤±æ•—ã€‚
# å…¶ä»–ï¼š
#  â€¢ ä¿æŒ v4.2 çš„ç©©å®šæ€§ï¼šå¤šä¸»æ©Ÿç´¢å¼•/è©³æƒ…ã€Referer å®Œæ•´ã€HEAD/Range æ¢æ¸¬ã€æ–·é»çºŒå‚³ã€å»é‡ã€è©³ç›¡æ—¥èªŒã€‚
# -----------------------------------------------------------------------------
# ç”¨æ³•ï¼š
#   bash smartedu_fetch_all.sh -p é«˜ä¸­
#   bash smartedu_fetch_all.sh -p é«˜ä¸­ -s è¯­æ–‡,æ•°å­¦ -m "å¿…ä¿® ç¬¬ä¸€å†Œ" -T 3
#   bash smartedu_fetch_all.sh -R -o ./output_dir
# =============================================================================

# ---- å¦‚æœä»¥ python æ–¹å¼èª¿ç”¨ï¼Œç›´æ¥è·³é Shell éƒ¨åˆ† ----
if [ -n "${PYTHON_EXEC:-}" ]; then
  :
else
  set -euo pipefail

  # èª¿è©¦æ¨¡å¼ï¼šDEBUG=1 æ™‚æ‰“å°åŸ·è¡Œç´°ç¯€
  if [ "${DEBUG:-0}" = "1" ]; then set -x; fi

  # è¨˜éŒ„ç•¶å‰å·¥ä½œç›®éŒ„ï¼Œé¿å… /dev/fd è·¯å¾‘é€ æˆç›¸å°è·¯å¾‘æ··äº‚
  PWD_ABS="$(pwd)"

  # å°æ–¼ apt ç³»çµ±ï¼Œé è¨­ç‚ºéäº’å‹•æ¨¡å¼ï¼Œé¿å…å®‰è£ä¸­é€”åœä¸‹
  if command -v apt-get >/dev/null 2>&1 || command -v apt >/dev/null 2>&1; then
    export DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-noninteractive}
  fi

  # é è¨­åƒæ•¸
  PHASE="é«˜ä¸­"
  SUBJECTS="è¯­æ–‡,æ•°å­¦,è‹±è¯­,æ€æƒ³æ”¿æ²»,å†å²,åœ°ç†,ç‰©ç†,åŒ–å­¦,ç”Ÿç‰©"
  MATCH=""
  IDS=""
  OUT_DIR=""
  ONLY_FAILED="0"
  HCON=12
  DCON=5
  LIMIT=""
  POST_RETRY=2
  AUTO_RUN="0"

  usage() {
    cat >&2 <<'USAGE'
ç”¨æ³•:
  bash smartedu_fetch_all.sh [é¸é …]

é¸é …:
  -p PHASE         æ•™è‚²éšæ®µï¼šå°å­¦|åˆä¸­|é«˜ä¸­|ç‰¹æ®Šæ•™è‚²|å°å­¦54|åˆä¸­54    (é è¨­: é«˜ä¸­)
  -s SUBJECTS      å­¸ç§‘é€—è™Ÿåˆ†éš” (é è¨­: è¯­æ–‡,æ•°å­¦,è‹±è¯­,æ€æƒ³æ”¿æ²»,å†å²,åœ°ç†,ç‰©ç†,åŒ–å­¦,ç”Ÿç‰©)
  -m KEYWORD       æ›¸åé—œéµè©ï¼ˆå­ä¸²åŒ¹é…ï¼Œå¯å¤šè©ä»¥ç©ºæ ¼åˆ†éš”ï¼‰
  -i IDS           æŒ‡å®š contentId åˆ—è¡¨ï¼Œé€—è™Ÿåˆ†éš”ï¼ˆè·³éç´¢å¼•éæ¿¾ï¼Œç›´é”ï¼‰
  -o OUT_DIR       è‡ªå®šç¾©è¼¸å‡ºç›®éŒ„ï¼ˆé è¨­: ./smartedu_textbooksï¼‰
  -R               åƒ…é‡è©¦ä¸Šæ¬¡å¤±æ•—ï¼ˆè®€ OUT_DIR/failed.jsonï¼‰
  -c N             è§£æç›´éˆä¸¦ç™¼ (HEAD æª¢æŸ¥)ï¼Œé è¨­ 12
  -d N             ä¸‹è¼‰ä¸¦ç™¼ï¼Œé è¨­ 5
  -n N             åªè™•ç†å‰ N æœ¬ï¼ˆèª¿è©¦ç”¨ï¼‰
  -T N             æ•´è¼ªçµæŸå¾Œè‡ªå‹•é‡è©¦ N è¼ªï¼ˆé è¨­ 2ï¼›0=é—œé–‰ï¼‰
  -y               éäº’å‹•ç›´è·‘ï¼ˆè·³éäº¤äº’é¸æ“‡ï¼Œä½¿ç”¨ç•¶å‰åƒæ•¸ï¼‰
  -h               é¡¯ç¤ºæ­¤å¹«åŠ©

ç¤ºä¾‹:
  bash smartedu_fetch_all.sh -p é«˜ä¸­
  bash smartedu_fetch_all.sh -p é«˜ä¸­ -s è¯­æ–‡,æ•°å­¦ -m "å¿…ä¿® ç¬¬ä¸€å†Œ" -T 3
  bash smartedu_fetch_all.sh -p å°å­¦54 -o ~/Downloads/textbooks
USAGE
  }

  while getopts ":p:s:m:i:o:Rc:d:n:T:hy" opt; do
    case "$opt" in
      p) PHASE="$OPTARG" ;;
      s) SUBJECTS="$OPTARG" ;;
      m) MATCH="$OPTARG" ;;
      i) IDS="$OPTARG" ;;
      o) OUT_DIR="$OPTARG" ;;
      R) ONLY_FAILED="1" ;;
      c) HCON="$OPTARG" ;;
      d) DCON="$OPTARG" ;;
      n) LIMIT="$OPTARG" ;;
      T) POST_RETRY="$OPTARG" ;;
      y) AUTO_RUN="1" ;;
      h) usage; exit 0 ;;
      :) echo "éŒ¯èª¤ï¼šé¸é … -$OPTARG éœ€è¦ä¸€å€‹åƒæ•¸ã€‚" >&2; usage; exit 2 ;;
      \?) echo "éŒ¯èª¤ï¼šæœªçŸ¥é¸é … -$OPTARG" >&2; usage; exit 2 ;;
    esac
  done

  # ---- äº¤äº’å¼é…ç½®ï¼ˆé»˜èªé–‹å•Ÿï¼›ç”¨ -y è·³éï¼‰ ----
  if [ "$AUTO_RUN" != "1" ] && [ -t 0 ]; then
    printf "\n================ ä¸‹è¼‰é…ç½®åš®å° ================\n"
    printf "åªéœ€é¸æ“‡ æ•™è‚²éšæ®µ å’Œ å­¸ç§‘ï¼›å…¶é¤˜ä¿æŒé»˜èªä¸¦è‡ªå‹•é–‹å§‹ã€‚\n"

    # æ•™è‚²éšæ®µï¼ˆæ•¸å­—é¸æ“‡ï¼‰
    printf "\n[1] æ•™è‚²éšæ®µï¼š\n"
    printf "   1) å°å­¦    2) åˆä¸­    3) é«˜ä¸­    4) ç‰¹æ®Šæ•™è‚²    5) å°å­¦54    6) åˆä¸­54\n"
    read -r -p "è¼¸å…¥æ•¸å­— 1-6ï¼ˆé»˜èª: $PHASEï¼‰: " ans
    case "$ans" in
      1) PHASE="å°å­¦";;
      2) PHASE="åˆä¸­";;
      3) PHASE="é«˜ä¸­";;
      4) PHASE="ç‰¹æ®Šæ•™è‚²";;
      5) PHASE="å°å­¦54";;
      6) PHASE="åˆä¸­54";;
      "") : ;;
      *) printf "[i] éæ³•é¸æ“‡ï¼Œä¿æŒ: %s\n" "$PHASE";;
    esac

    # å­¸ç§‘ï¼ˆåƒ…æ­¤ä¸€æ­¥ï¼›ç•™ç©ºæ²¿ç”¨ç•¶å‰é è¨­ï¼‰
    printf "\n[2] å­¸ç§‘ï¼ˆé€—è™Ÿåˆ†éš”ï¼Œç•™ç©º=å…¨éƒ¨é è¨­ï¼‰\n"
    printf "    ç•¶å‰: %s\n" "$SUBJECTS"
    read -r -p "è¼¸å…¥å­¸ç§‘: " ans
    [ -n "$ans" ] && SUBJECTS="$ans"

    # ç›´æ¥é–‹å§‹â€”â€”ä¸å†è©¢å•ï¼šåƒ…é‡è©¦/é™åˆ¶/é‡è©¦è¼ªæ•¸/è¼¸å‡ºç›®éŒ„/ç¢ºèª
  fi

  # äº¤äº’è¼¸å…¥å¾Œå†åšä¸€æ¬¡æ•¸å€¼æ ¡é©—
  int_re='^[0-9]+$'
  if ! [[ "$HCON" =~ $int_re ]]; then echo "[!] -c å¿…é ˆç‚ºæ•´æ•¸" >&2; exit 2; fi
  if ! [[ "$DCON" =~ $int_re ]]; then echo "[!] -d å¿…é ˆç‚ºæ•´æ•¸" >&2; exit 2; fi
  if [[ -n "$LIMIT" ]] && ! [[ "$LIMIT" =~ $int_re ]]; then echo "[!] -n å¿…é ˆç‚ºæ•´æ•¸" >&2; exit 2; fi
  if ! [[ "$POST_RETRY" =~ $int_re ]]; then echo "[!] -T å¿…é ˆç‚ºæ•´æ•¸" >&2; exit 2; fi

  # --- æ¬Šé™èˆ‡åŒ…ç®¡ç†å™¨åµæ¸¬ ---
  if [ "${EUID:-$(id -u)}" -ne 0 ]; then SUDO="sudo"; else SUDO=""; fi
  have() { command -v "$1" >/dev/null 2>&1; }
  pm=""
  if have apt-get; then pm=apt; elif have apt; then pm=apt; elif have dnf; then pm=dnf; elif have yum; then pm=yum; elif have pacman; then pm=pacman; elif have zypper; then pm=zypper; elif have apk; then pm=apk; elif have brew; then pm=brew; fi

  # --- å®‰è£ Python èˆ‡ pip/venvï¼Œæ¶µè“‹ä¸»æµç™¼è¡Œç‰ˆ ---
  install_python() {
    echo "[*] æº–å‚™ Python ç’°å¢ƒ... (pkgmgr=$pm)"
    case "$pm" in
      apt)
        $SUDO apt-get update -y -qq || true
        if [ -n "$SUDO" ]; then
          $SUDO env DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-noninteractive} \
            apt-get install -y -qq \
              -o Dpkg::Options::=--force-confdef \
              -o Dpkg::Options::=--force-confnew \
              python3 python3-venv python3-pip ca-certificates
        else
          env DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-noninteractive} \
            apt-get install -y -qq \
              -o Dpkg::Options::=--force-confdef \
              -o Dpkg::Options::=--force-confnew \
              python3 python3-venv python3-pip ca-certificates
        fi
        ;;
      dnf)
        $SUDO dnf install -y python3 python3-pip
        ;;
      yum)
        $SUDO yum install -y python3 python3-pip
        ;;
      pacman)
        $SUDO pacman -Sy --noconfirm python python-pip
        ;;
      zypper)
        $SUDO zypper -n install python3 python3-pip
        ;;
      apk)
        $SUDO apk add --no-cache python3 py3-pip ca-certificates
        ;;
      brew)
        brew update >/dev/null || true
        brew install python || true
        ;;
      *)
        echo "[!] æœªè­˜åˆ¥çš„åŒ…ç®¡ç†å™¨ï¼Œè«‹æ‰‹å‹•å®‰è£ python3/pipã€‚" >&2
        ;;
    esac

    # è‹¥ç¼º ensurepipï¼Œå˜—è©¦ä¿®å¾©
    if ! python3 - <<'PY' 2>/dev/null
import ensurepip; print('ok')
PY
    then
      echo "[*] å˜—è©¦å•Ÿç”¨ ensurepip..."
      python3 -m ensurepip --upgrade >/dev/null 2>&1 || true
    fi

    # è‹¥ä»ç„¡ pipï¼Œä½¿ç”¨ get-pip å¼•å°
    if ! python3 -m pip --version >/dev/null 2>&1; then
      echo "[*] ä½¿ç”¨ get-pip å¼•å°å®‰è£ pip..."
      TMPPIP="$(mktemp -t getpip_XXXX).py"
      if have curl; then curl -fsSL https://bootstrap.pypa.io/get-pip.py -o "$TMPPIP"; elif have wget; then wget -qO "$TMPPIP" https://bootstrap.pypa.io/get-pip.py; else echo "[!] éœ€è¦ curl æˆ– wget ä¸‹è¼‰ get-pip.py" >&2; exit 1; fi
      python3 "$TMPPIP" >/dev/null
      rm -f "$TMPPIP"
    fi
  }

  if ! have python3; then
    if [ -z "$pm" ]; then echo "[!] æœªæª¢æ¸¬åˆ°åŒ…ç®¡ç†å™¨ä¸”ç³»çµ±ç„¡ python3ï¼Œè«‹å…ˆæ‰‹å‹•å®‰è£ã€‚" >&2; exit 1; fi
    install_python
  else
    # æŸäº› Debian/Ubuntu ç²¾ç°¡é¡åƒé›–æœ‰ python3 ä½†ç¼º venv æ¨¡å¡Š
    if [ "$pm" = apt ] && ! python3 -c 'import venv' 2>/dev/null; then
      echo "[*] å®‰è£ python3-venv ..."; $SUDO apt-get update -y -qq; \
      if [ -n "$SUDO" ]; then
        $SUDO env DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-noninteractive} apt-get install -y -qq python3-venv
      else
        env DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-noninteractive} apt-get install -y -qq python3-venv
      fi
    fi
    # è‹¥ç„¡ pip äº¦è£œé½Š
    if ! python3 -m pip --version >/dev/null 2>&1; then
      install_python
    fi
  fi

  # --- å»ºç«‹è™›æ“¬ç’°å¢ƒï¼ˆå¤±æ•—å‰‡ä¿®å¾©å¾Œé‡è©¦ï¼Œä»å¤±æ•— fallback ç³»çµ± Pythonï¼‰ ---
  # å…è¨±å¤–éƒ¨å¼·åˆ¶ä½¿ç”¨ç³»çµ± Pythonï¼šUSE_SYSTEM_PY=1 bash jks.sh ...
  if [ "${USE_SYSTEM_PY:-0}" = "1" ]; then
    echo "[i] å·²æŒ‡å®š USE_SYSTEM_PY=1ï¼Œè·³é venv æ§‹å»ºï¼Œç›´æ¥ä½¿ç”¨ç³»çµ± Pythonã€‚"
  fi

  VENV_DIR="${VENV_DIR:-$PWD_ABS/.venv}"
  if [ "${USE_SYSTEM_PY:-0}" != "1" ]; then
    if [ ! -d "$VENV_DIR" ]; then
      echo "[*] å‰µå»ºè™›æ“¬ç’°å¢ƒ $VENV_DIR"
      if ! python3 -m venv "$VENV_DIR" 2>/tmp/venv.err; then
        echo "[!] venv å»ºç«‹å¤±æ•—ï¼Œå˜—è©¦ä¿®å¾©..."
        if [ "$pm" = apt ]; then
          if [ -n "$SUDO" ]; then
            $SUDO env DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-noninteractive} apt-get install -y -qq python3-venv || true
          else
            env DEBIAN_FRONTEND=${DEBIAN_FRONTEND:-noninteractive} apt-get install -y -qq python3-venv || true
          fi
        fi
        python3 -m ensurepip --upgrade >/dev/null 2>&1 || true
        if ! python3 -m venv "$VENV_DIR" 2>>/tmp/venv.err; then
          echo "[!] ä»ç„¡æ³•å»ºç«‹ venvï¼Œå°‡æ”¹ç”¨ç³»çµ± Python ç¹¼çºŒï¼ˆå»ºè­°ç¨å¾Œä¿®å¾© venvï¼‰ã€‚" >&2
          USE_SYSTEM_PY=1
        fi
      fi
    fi
  fi

  if [ "${USE_SYSTEM_PY:-0}" != "1" ]; then
    if [ -f "$VENV_DIR/bin/activate" ] && [ -x "$VENV_DIR/bin/python3" ]; then
      # shellcheck disable=SC1091
      . "$VENV_DIR/bin/activate"
      echo "[i] å·²å•Ÿç”¨è™›æ“¬ç’°å¢ƒï¼š$VENV_DIR"
    else
      echo "[!] venv æ§‹å»ºä¸å®Œæ•´ï¼Œæ‰¾ä¸åˆ° $VENV_DIR/bin/activate æˆ– python3ï¼›å°‡æ”¹ç”¨ç³»çµ± Python ç¹¼çºŒã€‚" >&2
      USE_SYSTEM_PY=1
      if [ -f /tmp/venv.err ]; then
        echo "[i] venv å»ºç«‹éŒ¯èª¤æ‘˜è¦ï¼š" >&2
        tail -n 50 /tmp/venv.err >&2 || true
      fi
      echo "[i] ç•¶å‰å·¥ä½œç›®éŒ„ï¼š$PWD_ABSï¼›VENV_DIR=$VENV_DIR"
      echo "[i] ç›®éŒ„åˆ—èˆ‰ï¼š"; ls -la "$PWD_ABS" || true
    fi
  fi

  # å®‰è£ä¾è³´
  echo "[i] ä½¿ç”¨çš„ Python: $(command -v python3)"
  python3 --version || true
  python3 -m pip install -U pip wheel setuptools >/dev/null
  python3 -m pip install -U aiohttp aiofiles tqdm >/dev/null

  export SMARTEDU_PHASE="$PHASE"
  export SMARTEDU_SUBJ="$SUBJECTS"
  export SMARTEDU_MATCH="$MATCH"
  export SMARTEDU_IDS="$IDS"
  export SMARTEDU_OUT_DIR="${OUT_DIR:-./smartedu_textbooks}"
  export SMARTEDU_ONLY_FAILED="$ONLY_FAILED"
  export SMARTEDU_HCON="$HCON"
  export SMARTEDU_DCON="$DCON"
  export SMARTEDU_LIMIT="$LIMIT"
  export SMARTEDU_POST_RETRY="$POST_RETRY"
  export PYTHON_EXEC=1

  echo "[ğŸš€] å•Ÿå‹• Python ä¸‹è¼‰å™¨..."
  TMP_PY="$(mktemp)"
  awk '/^# >>>PYTHON>>>$/{p=1;next} /^# <<<PYTHON<<</{p=0} p' "$0" > "$TMP_PY"
  exec python3 "$TMP_PY"
  echo "[!] ç„¡æ³•å•Ÿå‹• Python å­é€²ç¨‹ï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹æ—¥èªŒã€‚" >&2
  exit 1
fi

# >>>PYTHON>>>
# -*- coding: utf-8 -*-
"""
SmartEdu æ‰¹é‡ä¸‹è¼‰å™¨ (polyglot v4.3)
- æ•´è¼ªçµæŸå¾Œè‡ªå‹•é‡è©¦ N è¼ªï¼ˆé è¨­ 2ï¼Œç’°å¢ƒè®Šé‡ SMARTEDU_POST_RETRY æˆ– -T èª¿æ•´ï¼‰ã€‚
"""
from __future__ import annotations

import os, re, json, asyncio, aiohttp, aiofiles, time, logging, traceback
from logging import handlers
from pathlib import Path
from urllib.parse import quote
from typing import List, Dict, Any, Tuple, Optional
from collections import namedtuple
from tqdm import tqdm

# ---------------- HTML ç´¢å¼•ç”Ÿæˆ ----------------

async def write_html(out_dir: Path, items: List[Dict[str, Any]], failed: List[Dict[str, Any]]):
    # æ§‹å»ºä¸»é¡Œé›†åˆèˆ‡æ¢ç›® HTML
    def esc(s: str) -> str:
        return (s or "").replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")

    subjects = sorted({it.get("subject", "ç¶œåˆ") for it in items})
    li_ok = []
    for it in items:
        p = Path(it.get("path", ""))
        try:
            rel = os.path.relpath(p, out_dir)
        except Exception:
            rel = p.name
        href = quote(rel.replace(os.sep, "/"), safe="/")
        li_ok.append(f'<li data-subj="{esc(it.get("subject",""))}" data-title="{esc(it.get("title",""))}">'
                     f'<a href="{href}" target="_blank" download>{esc(it.get("title","æœªå‘½åæ•™æ"))}</a>'
                     f'<span class="subj">{esc(it.get("subject",""))}</span>'
                     '</li>')

    li_fail = []
    for it in failed or []:
        p = Path(it.get("path", ""))
        try:
            rel = os.path.relpath(p, out_dir)
        except Exception:
            rel = p.name
        href = quote(rel.replace(os.sep, "/"), safe="/")
        li_fail.append(f'<li data-subj="{esc(it.get("subject",""))}" data-title="{esc(it.get("title",""))}">'
                       f'<a href="{href}" target="_blank">{esc(it.get("title","æœªå‘½åæ•™æ"))}</a>'
                       f' <code>æœªå®Œæˆ/å¤±æ•—</code>'
                       '</li>')

    html = f"""<!doctype html>
<html lang=zh-CN>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<title>SmartEdu æœ¬åœ°æ•™æç´¢å¼•</title>
<style>
  :root {{ --bg:#0b0d10; --fg:#e6edf3; --muted:#9aa4ad; --accent:#6ab7ff; --chip:#1f2937; }}
  * {{ box-sizing: border-box; }}
  body {{ margin:0; font:14px/1.6 -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'PingFang SC', 'Noto Sans CJK SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif; background:var(--bg); color:var(--fg); }}
  header {{ padding:16px 20px; border-bottom:1px solid #11161c; position:sticky; top:0; background:rgba(11,13,16,.9); backdrop-filter: blur(8px); }}
  h1 {{ margin:0 0 6px; font-size:18px; }}
  .muted {{ color:var(--muted); }}
  .row {{ display:flex; flex-wrap:wrap; gap:10px; align-items:center; }}
  select, input[type="search"] {{ background:#0f141a; color:var(--fg); border:1px solid #17212b; border-radius:8px; padding:8px 10px; outline:none; min-width:180px; }}
  main {{ padding:18px 20px; }}
  ul {{ list-style:none; padding:0; margin:0; display:grid; grid-template-columns: repeat(auto-fill, minmax(280px,1fr)); gap:10px; }}
  li {{ background:#0f141a; border:1px solid #161f29; border-radius:10px; padding:10px 12px; display:flex; justify-content:space-between; align-items:center; gap:10px; }}
  li a {{ color:var(--fg); text-decoration:none; }}
  li a:hover {{ color:var(--accent); text-decoration:underline; }}
  li .subj {{ color:var(--muted); font-size:12px; background:var(--chip); padding:2px 6px; border-radius:999px; }}
  section {{ margin-top:22px; }}
  code {{ background:#111820; color:#c9defc; padding:2px 6px; border-radius:6px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }}
</style>
</head>
<body>
  <header>
    <h1>SmartEdu æœ¬åœ°æ•™æç´¢å¼•</h1>
    <div class=row>
      <div class=muted>å…± <b id=cntAll>{len(items)}</b> æœ¬ï¼›å¤±æ•— <b id=cntFail>{len(failed or [])}</b> æœ¬</div>
      <select id=selSubj>
        <option value="">å…¨éƒ¨å­¸ç§‘</option>
        {''.join(f'<option value="{esc(s)}">{esc(s)}</option>' for s in subjects)}
      </select>
      <input id=kw type=search placeholder="é—œéµè©éæ¿¾ï¼ˆæ›¸åï¼‰">
    </div>
  </header>
  <main>
    <section>
      <h3 class=muted>å·²å®Œæˆ</h3>
      <ul id=listOk>
        {''.join(li_ok)}
      </ul>
    </section>
    <section>
      <h3 class=muted>æœªå®Œæˆ/å¤±æ•—</h3>
      <ul id=listFail>
        {''.join(li_fail) if li_fail else '<li class="muted">ç„¡</li>'}
      </ul>
    </section>
  </main>
<script>
(function(){
  const sel=document.getElementById('selSubj');
  const kw=document.getElementById('kw');
  const listOk=document.getElementById('listOk');
  const listFail=document.getElementById('listFail');
  function apply(){
    const s=sel.value.trim();
    const k=kw.value.trim().toLowerCase();
    for(const ul of [listOk, listFail]){
      for(const li of ul.querySelectorAll('li')){
        const subj=li.getAttribute('data-subj')||'';
        const title=(li.getAttribute('data-title')||'').toLowerCase();
        const okSubj=!s || subj.includes(s);
        const okKw=!k || title.includes(k);
        li.style.display=(okSubj && okKw)?'flex':'none';
      }
    }
  }
  sel.addEventListener('change', apply);
  kw.addEventListener('input', apply);
})();
</script>
</body>
</html>
"""
    async with aiofiles.open(out_dir / "index.html", "w", encoding="utf-8") as f:
        await f.write(html)

# ---------------- è¨­å®š ----------------
Settings = namedtuple("Settings", [
    "PHASE", "SUBJECTS", "MATCH", "IDS", "OUT_DIR", "ONLY_FAILED",
    "HCON", "DCON", "LIMIT", "POST_RETRY"
])

def load_settings_from_env() -> Settings:
    out_env = os.getenv("SMARTEDU_OUT_DIR")
    out_dir = Path(os.path.expanduser(out_env)) if out_env else Path.cwd() / "smartedu_textbooks"
    pr_raw = os.getenv("SMARTEDU_POST_RETRY", "2").strip()
    try:
        pr = max(0, min(5, int(pr_raw)))  # 0..5 åˆç†ç¯„åœ
    except ValueError:
        pr = 2
    return Settings(
        PHASE=os.getenv("SMARTEDU_PHASE", "é«˜ä¸­"),
        SUBJECTS=[s.strip() for s in os.getenv("SMARTEDU_SUBJ", "è¯­æ–‡,æ•°å­¦,è‹±è¯­,æ€æƒ³æ”¿æ²»,å†å²,åœ°ç†,ç‰©ç†,åŒ–å­¦,ç”Ÿç‰©").split(",") if s.strip()],
        MATCH=os.getenv("SMARTEDU_MATCH", "").strip(),
        IDS=[s.strip() for s in os.getenv("SMARTEDU_IDS", "").split(",") if s.strip()],
        OUT_DIR=out_dir,
        ONLY_FAILED=os.getenv("SMARTEDU_ONLY_FAILED", "0") == "1",
        HCON=int(os.getenv("SMARTEDU_HCON", "12")),
        DCON=int(os.getenv("SMARTEDU_DCON", "5")),
        LIMIT=int(raw) if (raw := os.getenv("SMARTEDU_LIMIT", "").strip()).isdigit() else None,
        POST_RETRY=pr,
    )

S_FILE_HOSTS = [
    "https://s-file-1.ykt.cbern.com.cn",
    "https://s-file-2.ykt.cbern.com.cn",
    "https://s-file-3.ykt.cbern.com.cn",
]
R_HOSTS = [
    "https://r1-ndr-oversea.ykt.cbern.com.cn",
    "https://r2-ndr-oversea.ykt.cbern.com.cn",
    "https://r3-ndr-oversea.ykt.cbern.com.cn",
    "https://r1-ndr.ykt.cbern.com.cn",
    "https://r2-ndr.ykt.cbern.com.cn",
    "https://r3-ndr.ykt.cbern.com.cn",
]
ENTRY_PATH = "/zxx/ndrs/resources/tch_material/version/data_version.json"
BASE_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_6_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118 Safari/537.36",
    "Accept": "application/json, text/plain, */*",
    "Accept-Language": "zh-CN,zh;q=0.9",
}
PHASE_TAGS = {
    "å°å­¦": ["å°å­¦"],
    "åˆä¸­": ["åˆä¸­"],
    "é«˜ä¸­": ["é«˜ä¸­", "æ™®é€šé«˜ä¸­"],
    "ç‰¹æ®Šæ•™è‚²": ["ç‰¹æ®Šæ•™è‚²"],
    "å°å­¦54": ["å°å­¦ï¼ˆäº”â€¢å››å­¦åˆ¶ï¼‰", "å°å­¦ï¼ˆäº”Â·å››å­¦åˆ¶ï¼‰"],
    "åˆä¸­54": ["åˆä¸­ï¼ˆäº”â€¢å››å­¦åˆ¶ï¼‰", "åˆä¸­ï¼ˆäº”Â·å››å­¦åˆ¶ï¼‰"],
}

# ---------------- æ—¥èªŒ ----------------
LOGGER = logging.getLogger("smartedu")

def setup_logging(out_dir: Path):
    LOGGER.setLevel(logging.DEBUG)
    LOGGER.handlers.clear()
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch.setFormatter(logging.Formatter("[%(asctime)s] %(levelname)s - %(message)s", datefmt="%H:%M:%S"))
    out_dir.mkdir(parents=True, exist_ok=True)
    fh = handlers.RotatingFileHandler(out_dir / "smartedu_download.log", maxBytes=10_000_000, backupCount=2, encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    fh.setFormatter(logging.Formatter("[%(asctime)s] %(levelname)s %(name)s:%(lineno)d - %(message)s", datefmt="%Y-%m-%d %H:%M:%S"))
    LOGGER.addHandler(ch)
    LOGGER.addHandler(fh)

# ---------------- å°å·¥å…· ----------------

def safe_name(s: str) -> str:
    s = re.sub(r'[\\/:*?"<>|]', "_", (s or "").strip())
    return re.sub(r"\s+", " ", s) or "æœªå‘½åæ•™æ"


def book_tags(book: Dict[str, Any]) -> List[str]:
    return [t.get("tag_name", "") for t in (book.get("tag_list") or [])]


def match_phase_subject_keyword(book: Dict[str, Any], settings: Settings) -> bool:
    tags = book_tags(book)
    wants_phase = PHASE_TAGS.get(settings.PHASE, [])
    if wants_phase and not any(any(w in t for w in wants_phase) for t in tags):
        return False
    if settings.SUBJECTS and not any(any(s in t for s in settings.SUBJECTS) for t in tags):
        return False
    if settings.MATCH:
        title = (book.get("title") or (book.get("global_title") or {}).get("zh-CN") or "").lower()
        if not all(k.lower() in title for k in settings.MATCH.split()):
            return False
    return True


async def get_json(session: aiohttp.ClientSession, url: str) -> Optional[Dict | List]:
    for i in range(3):
        try:
            async with session.get(url, headers=BASE_HEADERS, timeout=30) as resp:
                txt = await resp.text()
                if resp.status == 200 and ("json" in (resp.headers.get("Content-Type", "") or "").lower() or txt[:1] in "[{"):
                    return json.loads(txt)
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            LOGGER.debug("JSON è«‹æ±‚å¤±æ•— %s (%d/3): %s", url, i+1, e)
        await asyncio.sleep(1.2 * (i + 1))
    return None


async def get_data_urls(session: aiohttp.ClientSession) -> List[str]:
    for base in S_FILE_HOSTS:
        js = await get_json(session, base + ENTRY_PATH)
        if isinstance(js, dict):
            field = js.get("urls") or js.get("url")
            urls: List[str] = []
            if isinstance(field, str):
                urls = [u.strip() for u in field.split(",") if u.strip()]
            elif isinstance(field, list):
                urls = [str(u).strip() for u in field if str(u).strip()]
            if urls:
                return urls
    return []


async def fetch_all_books(session: aiohttp.ClientSession, urls: List[str]) -> List[Dict[str, Any]]:
    books: List[Dict[str, Any]] = []
    for url in urls:
        js = await get_json(session, url)
        if isinstance(js, list):
            books.extend(js)
    return books


def build_referer(book_id: str) -> str:
    return ("https://basic.smartedu.cn/tchMaterial/detail"
            f"?contentType=assets_document&contentId={book_id}"
            "&catalogType=tchMaterial&subCatalog=tchMaterial")


def derive_filename(item: dict, book_id: str) -> Optional[str]:
    stor = item.get("ti_storage") or (item.get("ti_storages") or [None])[0]
    if isinstance(stor, str) and ".pkg/" in stor:
        tail = stor.replace("cs_path:${ref-path}", "").lstrip("/")
        fname = tail.split(".pkg/", 1)[-1]
        base = fname.split("/")[-1] if fname else None
        if base:
            return base
    fname = item.get("ti_filename")
    if isinstance(fname, str) and fname.lower().endswith(".pdf"):
        return fname.split("/")[-1]
    title = item.get("ti_title") or item.get("title")
    if isinstance(title, str) and title.strip():
        t = title.strip()
        if not t.lower().endswith(".pdf"):
            t += ".pdf"
        return t
    return None


def candidates_from_detail(book_id: str, items: List[dict]) -> List[str]:
    urls = []
    for it in items:
        if (it.get("ti_format") or it.get("format") or "").lower() != "pdf":
            continue
        fname = derive_filename(it, book_id)
        if not fname:
            continue
        raw = f"esp/assets/{book_id}.pkg/{fname}"
        enc = f"esp/assets/{book_id}.pkg/{quote(fname)}"
        for host in R_HOSTS:
            urls.append(f"{host}/edu_product/{raw}")
            urls.append(f"{host}/edu_product/{enc}")
    for host in R_HOSTS:
        urls.append(f"{host}/edu_product/esp/assets/{book_id}.pkg/pdf.pdf")
    # å»é‡
    seen, dedup = set(), []
    for u in urls:
        if u not in seen:
            seen.add(u); dedup.append(u)
    return dedup


async def resolve_candidates(session: aiohttp.ClientSession, book_id: str) -> List[str]:
    for base in S_FILE_HOSTS:
        js = await get_json(session, f"{base}/zxx/ndrv2/resources/tch_material/details/{book_id}.json")
        if isinstance(js, dict):
            items = js.get("ti_items") or []
            if items:
                return candidates_from_detail(book_id, items)
    return [f"{h}/edu_product/esp/assets/{book_id}.pkg/pdf.pdf" for h in R_HOSTS]


async def probe_url_exists(session: aiohttp.ClientSession, url: str, referer: str) -> bool:
    # å„ªå…ˆ HEADï¼›ä¸æ”¯æŒå‰‡ç”¨ Range=0-1 çš„ GETï¼ˆè¿”å› 206 è¦–ç‚ºå­˜åœ¨ï¼‰
    headers = {**BASE_HEADERS, "Referer": referer}
    try:
        async with session.head(url, headers=headers, timeout=20, allow_redirects=True) as r:
            if r.status == 200:
                ct = (r.headers.get("Content-Type", "") or "").lower()
                if "pdf" in ct or url.lower().endswith(".pdf"):
                    cl = r.headers.get("Content-Length")
                    if cl is None or int(cl) > 50 * 1024:
                        return True
    except Exception:
        pass
    # fallback
    try:
        headers["Range"] = "bytes=0-1"
        async with session.get(url, headers=headers, timeout=20, allow_redirects=True) as r:
            if r.status in (200, 206):
                ct = (r.headers.get("Content-Type", "") or "").lower()
                if "pdf" in ct or url.lower().endswith(".pdf"):
                    return True
    except Exception:
        return False
    return False


def is_valid_pdf(path: Path) -> bool:
    try:
        if not path.exists() or path.stat().st_size < 100 * 1024:
            return False
        with open(path, "rb") as f:
            head = f.read(5)
        return head == b"%PDF-"
    except Exception:
        return False


async def download_pdf(session: aiohttp.ClientSession, url: str, dest: Path, book_id: str) -> bool:
    # è‹¥å·²æœ‰å®Œæ•´æ–‡ä»¶ï¼Œè·³é
    if is_valid_pdf(dest):
        LOGGER.info("æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³é: %s", dest.name)
        return True
    tmp = dest.with_suffix(".part")
    start = tmp.stat().st_size if tmp.exists() else 0
    headers = {**BASE_HEADERS, "Referer": build_referer(book_id)}
    if start > 0:
        headers["Range"] = f"bytes={start}-"
    for attempt in range(3):
        try:
            async with session.get(url, headers=headers, timeout=180) as r:
                if r.status not in {200, 206}:
                    LOGGER.debug("ä¸‹è¼‰ HTTP %s: %s", r.status, url)
                    await asyncio.sleep(2.0 * (attempt + 1))
                    continue
                dest.parent.mkdir(parents=True, exist_ok=True)
                mode = "ab" if (start > 0 and r.status == 206) else "wb"
                async with aiofiles.open(tmp, mode) as f:
                    async for chunk in r.content.iter_chunked(1<<14):
                        await f.write(chunk)
                tmp.replace(dest)
                return is_valid_pdf(dest)
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            LOGGER.debug("ä¸‹è¼‰ç•°å¸¸ %s (try %d/3): %s", url, attempt+1, e)
            await asyncio.sleep(2.5 * (attempt + 1))
    LOGGER.warning("ä¸‹è¼‰å¤±æ•—: %s", url)
    return False


async def resolve_one(session: aiohttp.ClientSession, sem: asyncio.Semaphore, book: Dict[str, Any], subjects: List[str]) -> Optional[Tuple[str, str, str, str, Path]]:
    async with sem:
        bid = book.get("id") or book.get("content_id")
        if not bid:
            return None
        title = safe_name(book.get("title") or (book.get("global_title") or {}).get("zh-CN") or bid)
        tags = book_tags(book)
        subj = next((s for s in subjects if any(s in t for t in tags)), "ç¶œåˆ")
        cands = await resolve_candidates(session, bid)
        ref = build_referer(bid)
        for u in cands:
            if await probe_url_exists(session, u, ref):
                return (bid, title, subj, u, Path("/dev/null"))  # ä½”ä½ï¼Œå¯¦éš›è·¯å¾‘ç¨å¾Œç”Ÿæˆ
        return None


async def run_normal_mode(session: aiohttp.ClientSession, settings: Settings):
    # æ§‹å»ºæ›¸ç›®
    if settings.IDS:
        books = [{"id": i, "title": i, "tag_list": [{"tag_name": settings.PHASE}]} for i in settings.IDS]
    else:
        LOGGER.info("ğŸ” è®€å–é ç¨‹æ•¸æ“šç´¢å¼•...")
        data_urls = await get_data_urls(session)
        if not data_urls:
            LOGGER.error("ç„¡æ³•ç²å–æ•¸æ“šç´¢å¼• URL åˆ—è¡¨ï¼"); return
        all_books = await fetch_all_books(session, data_urls)
        LOGGER.info("ğŸ“š ç¸½æ›¸ç›®æ•¸: %d", len(all_books))
        books = [b for b in all_books if match_phase_subject_keyword(b, settings)]
    if settings.LIMIT is not None:
        books = books[:settings.LIMIT]
    LOGGER.info("ğŸ¯ ç¯©é¸å¾Œï¼Œæº–å‚™è™•ç† %d æœ¬æ›¸ã€‚", len(books))
    if not books:
        return

    # è§£æ
    sem_head = asyncio.Semaphore(settings.HCON)
    resolve_tasks = [asyncio.create_task(resolve_one(session, sem_head, b, settings.SUBJECTS)) for b in books]
    resolved_raw: List[Tuple[str, str, str, str, Path]] = []
    for fut in tqdm(asyncio.as_completed(resolve_tasks), total=len(resolve_tasks), desc="è§£æç›´éˆ", ncols=100):
        r = await fut
        if r: resolved_raw.append(r)
    LOGGER.info("ğŸ”— è§£æå®Œæˆï¼ˆç›´éˆæœ‰æ•ˆï¼‰: %d æœ¬", len(resolved_raw))

    # è®€å–æ—¢æœ‰ index.jsonï¼ŒæŒ‰ book_id é‡ç”¨å·²ä¸‹è¼‰è·¯å¾‘ï¼Œé¿å…ä¸‹ä¸€è¼ªæ”¹åå¾Œé‡ä¸‹
    existing_map: Dict[str, Path] = {}
    try:
        idx_path = settings.OUT_DIR / "index.json"
        if idx_path.exists():
            async with aiofiles.open(idx_path, "r", encoding="utf-8") as f:
                old_items = json.loads(await f.read())
            for it in old_items or []:
                bid0 = str(it.get("id", "")).strip()
                p0 = it.get("path")
                if bid0 and isinstance(p0, str) and p0.strip():
                    existing_map[bid0] = Path(p0)
    except Exception as e:
        LOGGER.debug("è®€å– index.json å¤±æ•—: %s", e)

    # å¡«å¯«å¯¦éš›ä¿å­˜è·¯å¾‘ï¼Œè™•ç†å‘½åè¡çªï¼›å„ªå…ˆæ²¿ç”¨æ—¢æœ‰è·¯å¾‘
    resolved: List[Tuple[str, str, str, str, Path]] = []
    used_paths = set(existing_map.values())
    collisions, reused = 0, 0
    for bid, title, subj, url, _ in resolved_raw:
        # è‹¥å·²æœ‰è¨˜éŒ„ï¼Œå„ªå…ˆæ²¿ç”¨ï¼ˆå³ä½¿æ–‡ä»¶æš«ä¸å®Œæ•´ä¹Ÿæœƒç”¨åŒä¸€è·¯å¾‘ä»¥ä¾¿çºŒå‚³ï¼‰
        if bid in existing_map:
            dest = existing_map[bid]
            reused += 1
        else:
            subj_dir = settings.OUT_DIR / subj
            base = subj_dir / f"{title}.pdf"
            dest = base
            # è‹¥èˆ‡æ—¢æœ‰è·¯å¾‘/æœ¬è¼ªè·¯å¾‘è¡çªï¼ˆæˆ–ç£ç¢Ÿå·²æœ‰åŒåï¼‰ï¼Œè¿½åŠ å…§å®¹IDå¾Œç¶´
            if dest in used_paths or base.exists():
                collisions += 1
                cand = subj_dir / f"{title}__{bid[:8]}.pdf"
                idx = 2
                while cand in used_paths or cand.exists():
                    cand = subj_dir / f"{title}__{bid[:8]}_{idx}.pdf"
                    idx += 1
                dest = cand
        used_paths.add(dest)
        resolved.append((bid, title, subj, url, dest))

    LOGGER.info("ğŸ”— è§£æå®Œæˆ: %d æœ¬ï¼›è¨ˆåŠƒä¸‹è¼‰: %d æœ¬ï¼ˆå‘½åè¡çªè‡ªå‹•è™•ç† %dï¼›æ²¿ç”¨æ—¢æœ‰è·¯å¾‘ %dï¼‰",
                len(resolved_raw), len(resolved), collisions, reused)

    # é æƒï¼šå·²å­˜åœ¨ä¸”æœ‰æ•ˆçš„ç›´æ¥è¨ˆå…¥æˆåŠŸæ¸…å–®ï¼Œä¸å»ºä¸‹è¼‰ä»»å‹™ï¼Œé¿å…å†æ¬¡å…¨é‡é€²åº¦æ¢
    index_success, failed_list = [], []
    already_ok: List[Tuple[str, str, str, str, Path]] = []
    work_list: List[Tuple[str, str, str, str, Path]] = []
    for meta in resolved:
        bid, title, subj, url, dest = meta
        if is_valid_pdf(dest):
            already_ok.append(meta)
            index_success.append({
                "id": bid, "title": title, "subject": subj,
                "pdf_url": url, "path": str(dest)
            })
        else:
            work_list.append(meta)

    LOGGER.info("ğŸ“¦ å·²å­˜åœ¨ä¸”æœ‰æ•ˆ: %dï¼Œæœ¬æ¬¡éœ€è¦ä¸‹è¼‰: %d", len(already_ok), len(work_list))

    # ä¸‹è¼‰ï¼ˆé¦–è¼ªï¼‰ï¼šåƒ…å°éœ€è¦ä¸‹è¼‰çš„é …ç›®å»ºç«‹ä»»å‹™
    success, failed = len(already_ok), 0
    if work_list:
        down_tasks = [asyncio.create_task(download_pdf(session, url, dest, bid)) for (bid, title, subj, url, dest) in work_list]
        for fut, meta in zip(tqdm(asyncio.as_completed(down_tasks), total=len(down_tasks), desc="PDF ä¸‹è¼‰", ncols=100), work_list):
            ok = await fut
            bid, title, subj, url, dest = meta
            if ok:
                success += 1
                index_success.append({"id": bid, "title": title, "subject": subj, "pdf_url": url, "path": str(dest)})
            else:
                failed += 1
                failed_list.append({"id": bid, "title": title, "subject": subj, "url": url, "path": str(dest)})
    else:
        LOGGER.info("ğŸ‰ å…¨éƒ¨æ–‡ä»¶å·²å®Œæ•´ï¼Œç„¡éœ€ä¸‹è¼‰ã€‚")

    # è‡ªå‹•é‡è©¦ï¼ˆåƒ…é‡å°å¤±æ•—é …ï¼‰
    rounds = settings.POST_RETRY
    for round_idx in range(1, rounds + 1):
        if not failed_list:
            break
        LOGGER.info("ğŸ” è‡ªå‹•é‡è©¦ ç¬¬ %d/%d è¼ªï¼šå¾…é‡è©¦ %d æœ¬", round_idx, rounds, len(failed_list))
        tasks = [asyncio.create_task(download_pdf(session, it["url"], Path(it["path"]), it["id"])) for it in failed_list]
        new_failed = []
        for fut, it in zip(tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=f"é‡è©¦è¼ª {round_idx}", ncols=100), list(failed_list)):
            if await fut:
                success += 1
                index_success.append({"id": it["id"], "title": it["title"], "subject": it["subject"], "pdf_url": it["url"], "path": it["path"]})
            else:
                new_failed.append(it)
        failed = len(new_failed)
        failed_list = new_failed
        if new_failed:
            await asyncio.sleep(1.0 * round_idx)  # è¼•å¾®é€€é¿

    # è¼¸å‡º
    async with aiofiles.open(settings.OUT_DIR / "index.json", "w", encoding="utf-8") as f:
        await f.write(json.dumps(index_success, ensure_ascii=False, indent=2))
    async with aiofiles.open(settings.OUT_DIR / "failed.json", "w", encoding="utf-8") as f:
        await f.write(json.dumps(failed_list, ensure_ascii=False, indent=2))
    # ç”Ÿæˆéœæ…‹ç¶²é ç´¢å¼•ï¼Œä½¿ç”¨æœ¬åœ°ç›¸å°è·¯å¾‘ï¼Œé¿å… 403 é˜²ç›œéˆ
    await write_html(settings.OUT_DIR, index_success, failed_list)
    LOGGER.info("ğŸŒ ç¶²é ç´¢å¼•: %s", settings.OUT_DIR / "index.html")

    retried = settings.POST_RETRY if settings.POST_RETRY else 0
    LOGGER.info("âœ… ç¸½çµï¼šæˆåŠŸ %dï¼Œä»å¤±æ•— %dï¼ˆè‡ªå‹•é‡è©¦è¼ªæ•¸ %dï¼‰", success, len(failed_list), retried)
    LOGGER.info("ğŸ“„ ç´¢å¼•: %s", settings.OUT_DIR / "index.json")
    if failed_list:
        LOGGER.warning("âš ï¸ ä»æœ‰ %d æœ¬ä¸‹è¼‰å¤±æ•—ã€‚å¯å†æ¬¡é‹è¡Œæœ¬è…³æœ¬ï¼ˆå°‡åƒ…çºŒå‚³æœªå®Œæˆéƒ¨åˆ†ï¼‰ï¼Œæˆ–ä½¿ç”¨ -R åƒ…é‡è©¦å¤±æ•—æ¸…å–®ã€‚", len(failed_list))


async def run_retry_mode(session: aiohttp.ClientSession, settings: Settings):
    failed_path = settings.OUT_DIR / "failed.json"
    if not failed_path.exists():
        LOGGER.error("é‡è©¦æ¨¡å¼å¤±æ•—ï¼šæœªæ‰¾åˆ° %s", failed_path); return
    async with aiofiles.open(failed_path, "r", encoding="utf-8") as f:
        items = json.loads(await f.read())
    if not items:
        LOGGER.info("ğŸ‰ å¤±æ•—è¨˜éŒ„ç‚ºç©ºï¼Œç„¡éœ€é‡è©¦ã€‚"); return
    tasks = [asyncio.create_task(download_pdf(session, it["url"], Path(it["path"]), it["id"])) for it in items]
    new_failed = []
    ok = 0
    for fut, it in zip(tqdm(asyncio.as_completed(tasks), total=len(tasks), desc="é‡è©¦ä¸‹è¼‰", ncols=100), items):
        if await fut:
            ok += 1
        else:
            new_failed.append(it)
    async with aiofiles.open(failed_path, "w", encoding="utf-8") as f:
        await f.write(json.dumps(new_failed, ensure_ascii=False, indent=2))
    LOGGER.info("âœ… é‡è©¦å®Œæˆï¼šæˆåŠŸ %dï¼Œä»å¤±æ•— %d", ok, len(new_failed))
    # é‡æ–°ç”Ÿæˆç´¢å¼•é 
    try:
        async with aiofiles.open(settings.OUT_DIR / "index.json", "r", encoding="utf-8") as f:
            items2 = json.loads(await f.read())
    except Exception:
        items2 = []
    await write_html(settings.OUT_DIR, items2, new_failed)
    LOGGER.info("ğŸŒ ç¶²é ç´¢å¼•: %s", settings.OUT_DIR / "index.html")


async def main():
    settings = load_settings_from_env()
    setup_logging(settings.OUT_DIR)
    LOGGER.info("ğŸ›ï¸ éšæ®µ:%s ç§‘ç›®:%s é—œéµè©:%s IDS:%d è‡ªå‹•é‡è©¦:%d", settings.PHASE, ",".join(settings.SUBJECTS) or "å…¨éƒ¨", settings.MATCH or "ç„¡", len(settings.IDS), settings.POST_RETRY)
    LOGGER.info("ğŸ“ ä¸‹è¼‰ç›®éŒ„: %s", settings.OUT_DIR)
    t0 = time.time()
    async with aiohttp.ClientSession(headers=BASE_HEADERS) as session:
        if settings.ONLY_FAILED:
            await run_retry_mode(session, settings)
        else:
            await run_normal_mode(session, settings)
    LOGGER.info("â±ï¸ ç¸½è€—æ™‚: %.2f ç§’", time.time() - t0)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ›” å·²æ‰‹å‹•ä¸­æ–·")
    except Exception:
        LOGGER.critical("è‡´å‘½éŒ¯èª¤:\n%s", traceback.format_exc())
# <<<PYTHON<<<